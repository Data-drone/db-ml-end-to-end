{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Notebook\n",
    "\n",
    "This represents a data engineering task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"environment\", \"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "CREATE CATALOG IF NOT EXISTS brian_ml_${environment};\n",
    "USE CATALOG brian_ml_${environment};\n",
    "CREATE SCHEMA IF NOT EXISTS warehouse;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = spark.read.format(\"delta\").load(\"/databricks-datasets/nyctaxi-with-zipcodes/subsampled\")\n",
    "display(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to select just 1 days worth of data so that we can run a regular timed job and populate the table bit by bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_datetime = raw_data \\\n",
    "    .select('tpep_pickup_datetime') \\\n",
    "    .agg(\n",
    "        F.min(F.col('tpep_pickup_datetime')).alias('first_date')\n",
    "    )\n",
    "\n",
    "min_date = min_datetime.collect()[0].first_date\n",
    "next_day = min_date + timedelta(days=1)\n",
    "next_day_midnight = next_day.replace(hour=0,minute=0,second=0)\n",
    "next_day_midnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the raw dataframe and create the table\n",
    "filtered_df = raw_data.filter(\n",
    "    F.col('tpep_pickup_datetime') <= next_day_midnight\n",
    ")\n",
    "print(f'collected {filtered_df.count()} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.write.mode('overwrite').saveAsTable(f'warehouse.raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "ALTER TABLE warehouse.raw_data SET TBLPROPERTIES (delta.enableChangeDataFeed = true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
